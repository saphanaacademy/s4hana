%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% "SAP S/4HANA: Extending with External Data" %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

***********************
* Hadoop/Hive Install *
***********************
# for the "SAP S/4HANA: Extending with External Data" lab, you have 2 options as your remote datasource ;
# - Hive in Hadoop
# - CSV Files
#
# it isn't mandatory to use hive, as you can use the fileformat adapter to complete the workshop
# however, to install hive on hadoop using ambari in aws, follow the following videos in the SAP HANA Vora 1.3 Playlist ;
# https://www.youtube.com/playlist?list=PLkzo92owKnVySPBoRJHfqNOOTQrnMrja2
# 
# - Vora 1.3: Create Linux Instance
# - Vora 1.3: Connect to Instance
# - Vora 1.3: Ambari Installation
# - Vora 1.3: Hadoop Installation
# - Vora 1.3: Hive Configuration
#
************************

****************
* Dropbox Link *
****************

# for Hive Data
wget https://www.dropbox.com/s/r2j63bo0o1jwtno/AirportWebServices.csv?dl=0 -O AirportWebServices.dat
# for File Formats Data
wget https://www.dropbox.com/s/w5kgc7nfga59ja8/AirportWebServices_FF.csv?dl=0
AirportWebServices.csv 

**********************
* HDFS/Hive Commands *
**********************

hdfs dfs -ls /apps/hive/warehouse/s4sha.db/
hdfs dfs -mkdir /apps/hive/warehouse/s4sha.db/
# hdfs dfs -rm -r /apps/hive/warehouse/s4sha.db/airportwebservices

DROP TABLE s4sha.airportwebservices;

CREATE DATABASE s4sha;

CREATE TABLE IF NOT EXISTS s4sha.airportwebservices (
airportcode                     char(3),
airportname                     varchar(100),
airportstate                    varchar(100),
airportcity                     varchar(100),
airportlat                      double,
airportlon                      double,
airportservice                  varchar(100) 
) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ;

hdfs dfs -put AirportWebServices.dat /apps/hive/warehouse/s4sha.db/airportwebservices
hdfs dfs -ls /apps/hive/warehouse/s4sha.db/airportwebservices
hdfs dfs -chown -R hive:hdfs /apps/hive/warehouse/s4sha.db

select * from s4sha.airportwebservices;

*************************
* SHAUSER User Creation *
*************************

CREATE USER SHAUSER PASSWORD Password1;
INSERT INTO _SYS_REPO.PACKAGE_CATALOG(PACKAGE_ID, SRC_SYSTEM, SRC_TENANT, DESCRIPTION, RESPONSIBLE, IS_STRUCTURAL) 
VALUES ('SHAUSER','HDB','','SHAUSER','SHAUSER',0);
GRANT EXECUTE ON REPOSITORY_REST TO SHAUSER;
GRANT EXECUTE ON GRANT_ACTIVATED_ROLE TO SHAUSER;
GRANT EXECUTE ON REVOKE_ACTIVATED_ROLE TO SHAUSER;
GRANT REPO.READ, REPO.EDIT_NATIVE_OBJECTS, REPO.ACTIVATE_NATIVE_OBJECTS, REPO.MAINTAIN_NATIVE_PACKAGES 
ON "SHAUSER" TO SHAUSER;
GRANT REPO.EDIT_IMPORTED_OBJECTS, REPO.ACTIVATE_IMPORTED_OBJECTS, REPO.MAINTAIN_IMPORTED_PACKAGES 
ON "SHAUSER" TO SHAUSER;

GRANT CREATE REMOTE SOURCE TO SHAUSER;
GRANT ADAPTER ADMIN TO SHAUSER;
GRANT AGENT ADMIN TO SHAUSER;

GRANT SELECT, INSERT, UPDATE, DELETE, EXECUTE ON SCHEMA SHAUSER to _SYS_REPO WITH GRANT OPTION;

### To delete user ###
# DELETE FROM _SYS_REPO.PACKAGE_CATALOG WHERE RESPONSIBLE = 'SHAUSER';
# SELECT TOP 1000 * FROM "_SYS_REPO"."PACKAGE_CATALOG" WHERE PACKAGE_ID = 'SHAUSER';
# DROP USER SHAUSER CASCADE;

*********************
* URL to Hive JDBCs *
*********************

http://repo.hortonworks.com/content/repositories/releases/org/apache/hive/hive-jdbc/

***************************
* Hive Remote Data Source *
***************************

DROP REMOTE SOURCE "Hadoop" CASCADE;

CREATE REMOTE SOURCE "Hadoop" ADAPTER "HiveAdapter" AT LOCATION AGENT "Agent"
CONFIGURATION
'<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<ConnectionProperties name="configurations">
    <PropertyGroup name="connectionInfo">
        <PropertyEntry name="HOST">**.**.**.**</PropertyEntry>
        <PropertyEntry name="PORT">10000</PropertyEntry>
        <PropertyEntry name="DB_NAME">s4sha</PropertyEntry>
        <PropertyEntry name="VERSION">1.2.1</PropertyEntry>
    </PropertyGroup>
    <PropertyGroup name="security">
            <PropertyEntry name="USE_SSL">false</PropertyEntry>
    </PropertyGroup>
</ConnectionProperties>'
WITH CREDENTIAL TYPE 'PASSWORD' USING
'<CredentialEntry name="credential">
    <user>hive</user>
    <password>hive</password>
</CredentialEntry>';

***************************
* File Format Data Source *
***************************

http://scn.sap.com/community/developer-center/hana/blog/2016/01/06/hana-smart-data-integration--the-file-adapter

data / csv file is available from here:
https://www.dropbox.com/s/r2j63bo0o1jwtno/AirportWebServices.csv?dl=0

copy (instead of download) the AirportWebservices data from here:
https://raw.githubusercontent.com/saphanaacademy/s4hana/master/AirportWebservices.csv
and paste it into a AirportWebservices.csv file in your d:\_FileFormat\ folder

the header has been added to the csv file already.

cd C:\usr\sap\dataprovagent\agentutils

createfileformat.bat -file d:\_FileFormat\Airportwebservices.csv -cfgdir d:\_FileFormat\

DROP REMOTE SOURCE "File" CASCADE;

CREATE REMOTE SOURCE "File" 
ADAPTER "FileAdapter" AT LOCATION AGENT "SDI_AGENT"
CONFIGURATION '<?xml version="1.0" encoding="UTF-8"?>
<ConnectionProperties name="ConnectionInfo">
<PropertyEntry name="rootdir">D:\_FileFormat\</PropertyEntry>
<PropertyEntry name="fileformatdir">D:\_FileFormat\</PropertyEntry>
</ConnectionProperties>'
WITH CREDENTIAL TYPE 'PASSWORD' USING
  '<CredentialEntry name="AccessTokenEntry">
    <password>S-1-5-21-*********-*********-500</password>
  </CredentialEntry>';
